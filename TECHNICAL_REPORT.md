# 📊 Qwen3-VL-2B-Instruct 技术说明文档

> 基准测试时间: 2026-02-28T16:07:21.185273
> 推理后端: **transformers**
> 模型路径: `./Qwen3-VL-2B-Instruct`

---

## 1. 硬件与软件环境

| 项目 | 配置 |
|------|------|
| **操作系统** | Linux-5.15.0-97-generic-x86_64-with-glibc2.35 |
| **Python** | 3.12.3 |
| **PyTorch** | 2.8.0+cu128 |
| **CUDA** | 12.8 |
| **cuDNN** | 91002 |
| **GPU** | NVIDIA GeForce RTX 4090 |
| **GPU 显存** | 23.52 GB |
| **CPU 核心数** | 128 |
| **系统内存** | 1007.52 GB |
| **推理后端** | transformers |
| **最大生成 token** | 256 |

## 2. 资源占用（实测数据）

### 2.1 模型加载

| 指标 | 数值 |
|------|------|
| **加载耗时** | 8.73 秒 |
| **GPU 显存占用** | 3.96 GB |
| **GPU 显存增量** | 3.96 GB |
| **系统内存增量** | 0.58 GB |

### 2.2 推理资源占用

| 指标 | 数值 |
|------|------|
| **推理峰值显存（最大）** | 6.33 GB |
| **推理峰值显存（平均）** | 4.39 GB |
| **GPU 总显存** | 23.52 GB |

## 3. 推理延迟（实测数据）

### 3.1 汇总

| 指标 | 数值 |
|------|------|
| **平均总延迟** | 3.57 秒 |
| **平均首 token 延迟** | 0.41 秒 |
| **平均吞吐量** | 44.72 tokens/s |

### 3.2 各场景详细数据

| 场景 | 总耗时(s) | 首token延迟(s) | 生成tokens | 吞吐量(tok/s) | GPU峰值(GB) |
|------|-----------|----------------|------------|---------------|-------------|
| 纯文本短问答 | 0.907 | 0.028 | ~47 | 51.84 | 3.98 |
| 纯文本长回答 | 5.237 | 0.073 | ~256 | 48.88 | 4.01 |
| 图片理解 | 3.844 | 0.208 | ~168 | 43.71 | 4.04 |
| PDF文档解析(3页) | 6.385 | 2.077 | ~237 | 37.12 | 6.33 |
| 多轮对话-第1轮 | 0.143 | 0.035 | ~5 | 34.86 | 3.98 |
| 数学推理 | 4.932 | 0.035 | ~256 | 51.9 | 4.01 |

## 4. 输入输出示例（实际模型输出）

### 示例 1: 纯文本短问答

**用户输入：**
```
你好，请用两三句话介绍一下你自己。
```

**模型输出：**
```
你好！我是一个人工智能助手，名叫通义千问。我能够帮助你回答问题、创作文字、提供信息，甚至进行逻辑推理和创作。我致力于通过对话和互动，为你提供精准、有用的支持。
```

*耗时: 0.907s | 首token: 0.028s | 吞吐: 51.84 tok/s*

### 示例 2: 纯文本长回答

**用户输入：**
```
请详细解释什么是深度学习，包括其基本原理、主要架构（如CNN、RNN、Transformer）、训练过程以及在计算机视觉和自然语言处理中的应用。
```

**模型输出：**
```
深度学习（Deep Learning）是机器学习的一个子领域，它通过构建多层神经网络（深度网络）来模拟人脑的神经网络结构，从而在复杂数据任务中实现高精度的模式识别和预测。它广泛应用于计算机视觉、自然语言处理、语音识别、医疗诊断、自动驾驶等众多领域。以下是对深度学习的详细解释。

---

### 一、深度学习的基本原理

深度学习的核心思想是：**通过多层非线性变换，从原始数据中自动提取高层次的特征，从而实现对复杂任务的高效建模。**

1. **神经网络与层次化特征提取**：
   - 深度学习基于人工神经网络（Artificial Neural Networks, ANNs），特别是深层神经网络（Deep Neural Networks, DNNs）。
   - 通过多层（通常几十层到数千层）的神经元堆叠，模型能够自动学习数据的抽象特征，而无需人工设计特征。

2. **非线性激活函数**：
   - 深度学习依赖于非线性激活函数（如ReLU、Sigmoid、Tanh等），使得网络能够学习复杂的函数关系。
   - 例如，ReLU（Rectified
```

*耗时: 5.237s | 首token: 0.073s | 吞吐: 48.88 tok/s*

### 示例 3: 图片理解

**用户输入 [附带图片/视频]：**
```
请详细描述这张图片中的内容，包括颜色、形状和布局。
```

**模型输出：**
```
这是一张以浅蓝色为背景的、风格简约的示意图，其顶部中央有“Benchmark Test”（基准测试）的标题。

图片中包含三个颜色和形状各异的几何图形，它们以一种不规则的布局分布在画面中：

- **红色方形**：位于画面的左上角，是一个纯红色的正方形。
- **绿色圆形**：位于画面的右上部分，是一个纯绿色的圆形，其边缘有轻微的阴影效果，使其看起来有立体感。
- **蓝色矩形**：位于画面的下方中央，是一个纯蓝色的矩形，其宽度大于高度。

这三个图形在画面上没有重叠，它们的相对位置和颜色形成了一个清晰的视觉对比。整体构图简洁明了，没有其他复杂的元素或文字。
```

*耗时: 3.844s | 首token: 0.208s | 吞吐: 43.71 tok/s*

### 示例 4: PDF文档解析(3页)

**用户输入 [附带图片]：**
```
请总结这份文档的主要内容。
```

**模型输出：**
```
这份文档是关于一个名为“P D F”的测试的示例文本，旨在评估模型对文档的理解能力。文档内容主要介绍了人工智能（AI）和深度学习的概念。

以下是文档的主要内容总结：

- **文档目的**：这份文档是用于测试模型的P D F文档理解能力的示例文本。

- **人工智能 (AI)**：人工智能是计算机科学的一个分支，致力于创建能够模拟人类智能的系统。

- **深度学习**：深度学习是机器学习的一个子领域，它使用多层神经网络来学习数据的表示。

- **内容结构**：文档包含三个页面，每个页面都包含相同的内容，即关于人工智能和深度学习的定义和简介。

- **文本特征**：文档中的文本为中文，采用简洁的无衬线字体，排版清晰，背景为白色。

- **文档用途**：该文档旨在作为测试模型理解能力的示例，通过提供标准的定义和解释，来评估模型对技术概念的掌握程度。

总的来说，这份文档是一个用于评估模型理解能力的测试材料，其内容聚焦于人工智能和深度学习这两个核心概念。
```

*耗时: 6.385s | 首token: 2.077s | 吞吐: 37.12 tok/s*

### 示例 5: 多轮对话-第1轮

**用户输入：**
```
中国的首都是哪里？
```

**模型输出：**
```
中国的首都是北京。
```

*耗时: 0.143s | 首token: 0.035s | 吞吐: 34.86 tok/s*

### 示例 6: 数学推理

**用户输入：**
```
一个水池有两个进水管和一个出水管。进水管A每小时注入3吨水，进水管B每小时注入2吨水，出水管每小时排出1吨水。如果水池容量为40吨，从空池开始，需要多少小时才能注满？请列出计算过程。
```

**模型输出：**
```
我们来一步一步计算这个水池注满所需的时间。

### 已知条件：
- 进水管A：每小时注入 3 吨
- 进水管B：每小时注入 2 吨
- 出水管：每小时排出 1 吨
- 水池总容量：40 吨
- 初始水池为空

### 总进水量（每小时）：
A 和 B 同时工作，所以总进水速度是：
$$
3 + 2 = 5 \text{ 吨/小时}
$$

### 出水速度：
出水管每小时排出 1 吨

### 所以净进水量（每小时）：
$$
5 - 1 = 4 \text{ 吨/小时}
$$

### 水池注满所需时间：
$$
\frac{40 \text{ 吨}}{4 \text{ 吨/小时}} = 10 \text{ 小时}
$$

---

### 答案：
**需要 10 小时才能注满水池。**

✅ 计算过程如下：
- 每小时净进水：3 +
```

*耗时: 4.932s | 首token: 0.035s | 吞吐: 51.9 tok/s*

## 5. 已知限制

| 限制 | 说明 |
|------|------|
| **PDF 页数上限** | 默认仅处理前 5 页（`max_pages=5`），超长文档需手动截取 |
| **视频长度** | 受显存和 `max_model_len` 限制，建议视频不超过 30 秒 |
| **并发能力** | 单用户单请求，不支持多用户并发推理 |
| **Transformers 流式** | 支持逐 token 流式输出，体感延迟较低 |
| **URL 图片** | 仅支持直链图片 URL，不支持需要登录或 JS 渲染的页面 |
| **多轮上下文** | 历史消息全部拼接，超长对话可能触发 OOM 或被截断 |
| **CPU 模式** | 仅 Transformers 后端支持 `--cpu-only`，速度极慢，仅供调试 |
| **模型能力** | 2B 参数量为轻量版，复杂推理和长文本生成能力弱于更大模型 |
| **显存使用率** | 推理峰值占 GPU 总显存的 26.9%，长上下文或多图输入可能导致 OOM |

## 6. 性能优化建议

1. **显存不足时**：降低 `--max-model-len` 或 `--gpu-memory-utilization` 参数
2. **提升吞吐量**：使用 vLLM 后端（`--backend vllm`），适合批量推理场景
3. **降低延迟**：使用 Transformers 后端的流式输出，首 token 延迟更低
4. **长文档处理**：减少 PDF 页数或降低图片分辨率以节省显存
5. **多轮对话**：定期清空会话历史，避免上下文过长导致 OOM

---

*本文档由 `scripts/benchmark.py` 和 `scripts/generate_report.py` 自动生成*
*测试时间: 2026-02-28T16:07:21.185273*
