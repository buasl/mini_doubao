"""
æŠ€æœ¯è¯´æ˜æ–‡æ¡£ç”Ÿæˆè„šæœ¬

è¯»å– benchmark.py ç”Ÿæˆçš„ JSON ç»“æœæ–‡ä»¶ï¼Œè‡ªåŠ¨ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ€æœ¯è¯´æ˜æ–‡æ¡£ã€‚

Usage:
    python scripts/generate_report.py --input benchmark_results_transformers.json
    python scripts/generate_report.py --input benchmark_results_transformers.json --output TECHNICAL_REPORT.md
"""

import argparse
import json
import os
from datetime import datetime


def load_results(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def generate_report(data: dict) -> str:
    meta = data.get("metadata", {})
    sys_info = data.get("system_info", {})
    torch_info = data.get("torch_info", {})
    gpu_info = data.get("gpu_info_after_load", {})
    loading = data.get("model_loading", {})
    benchmarks = data.get("benchmarks", [])
    summary = data.get("resource_summary", {})

    backend = meta.get("backend", "unknown")
    model_path = meta.get("model_path", "unknown")
    timestamp = meta.get("timestamp", datetime.now().isoformat())

    lines = []

    # â”€â”€ æ ‡é¢˜ â”€â”€
    lines.append("# ğŸ“Š Qwen3-VL-2B-Instruct æŠ€æœ¯è¯´æ˜æ–‡æ¡£")
    lines.append("")
    lines.append(f"> åŸºå‡†æµ‹è¯•æ—¶é—´: {timestamp}")
    lines.append(f"> æ¨ç†åç«¯: **{backend}**")
    lines.append(f"> æ¨¡å‹è·¯å¾„: `{model_path}`")
    lines.append("")
    lines.append("---")
    lines.append("")

    # â”€â”€ 1. ç¡¬ä»¶ä¸è½¯ä»¶ç¯å¢ƒ â”€â”€
    lines.append("## 1. ç¡¬ä»¶ä¸è½¯ä»¶ç¯å¢ƒ")
    lines.append("")
    lines.append("| é¡¹ç›® | é…ç½® |")
    lines.append("|------|------|")
    lines.append(f"| **æ“ä½œç³»ç»Ÿ** | {sys_info.get('platform', 'N/A')} |")
    lines.append(f"| **Python** | {sys_info.get('python_version', 'N/A')} |")
    lines.append(f"| **PyTorch** | {torch_info.get('torch_version', 'N/A')} |")
    lines.append(f"| **CUDA** | {torch_info.get('cuda_version', 'N/A')} |")
    lines.append(f"| **cuDNN** | {torch_info.get('cudnn_version', 'N/A')} |")
    lines.append(f"| **GPU** | {gpu_info.get('device_name', 'N/A')} |")
    lines.append(f"| **GPU æ˜¾å­˜** | {gpu_info.get('total_memory_gb', 'N/A')} GB |")
    lines.append(f"| **CPU æ ¸å¿ƒæ•°** | {sys_info.get('cpu_count', 'N/A')} |")
    lines.append(f"| **ç³»ç»Ÿå†…å­˜** | {sys_info.get('total_ram_gb', 'N/A')} GB |")
    lines.append(f"| **æ¨ç†åç«¯** | {backend} |")
    lines.append(f"| **æœ€å¤§ç”Ÿæˆ token** | {meta.get('max_new_tokens', 'N/A')} |")
    lines.append("")

    # â”€â”€ 2. èµ„æºå ç”¨ â”€â”€
    lines.append("## 2. èµ„æºå ç”¨ï¼ˆå®æµ‹æ•°æ®ï¼‰")
    lines.append("")
    lines.append("### 2.1 æ¨¡å‹åŠ è½½")
    lines.append("")
    lines.append("| æŒ‡æ ‡ | æ•°å€¼ |")
    lines.append("|------|------|")
    lines.append(f"| **åŠ è½½è€—æ—¶** | {loading.get('load_time_seconds', 'N/A')} ç§’ |")
    lines.append(f"| **GPU æ˜¾å­˜å ç”¨** | {loading.get('gpu_memory_after_gb', 'N/A')} GB |")
    lines.append(f"| **GPU æ˜¾å­˜å¢é‡** | {loading.get('gpu_memory_delta_gb', 'N/A')} GB |")
    lines.append(f"| **ç³»ç»Ÿå†…å­˜å¢é‡** | {loading.get('system_memory_delta_gb', 'N/A')} GB |")
    lines.append("")

    lines.append("### 2.2 æ¨ç†èµ„æºå ç”¨")
    lines.append("")
    lines.append("| æŒ‡æ ‡ | æ•°å€¼ |")
    lines.append("|------|------|")
    lines.append(f"| **æ¨ç†å³°å€¼æ˜¾å­˜ï¼ˆæœ€å¤§ï¼‰** | {summary.get('inference_gpu_peak_max_gb', 'N/A')} GB |")
    lines.append(f"| **æ¨ç†å³°å€¼æ˜¾å­˜ï¼ˆå¹³å‡ï¼‰** | {summary.get('inference_gpu_peak_avg_gb', 'N/A')} GB |")
    lines.append(f"| **GPU æ€»æ˜¾å­˜** | {summary.get('gpu_total_memory_gb', 'N/A')} GB |")
    lines.append("")

    # â”€â”€ 3. æ¨ç†å»¶è¿Ÿ â”€â”€
    lines.append("## 3. æ¨ç†å»¶è¿Ÿï¼ˆå®æµ‹æ•°æ®ï¼‰")
    lines.append("")
    lines.append("### 3.1 æ±‡æ€»")
    lines.append("")
    lines.append("| æŒ‡æ ‡ | æ•°å€¼ |")
    lines.append("|------|------|")
    lines.append(f"| **å¹³å‡æ€»å»¶è¿Ÿ** | {summary.get('avg_total_time_seconds', 'N/A')} ç§’ |")
    lines.append(f"| **å¹³å‡é¦– token å»¶è¿Ÿ** | {summary.get('avg_ttft_seconds', 'N/A')} ç§’ |")
    lines.append(f"| **å¹³å‡ååé‡** | {summary.get('avg_tokens_per_second', 'N/A')} tokens/s |")
    lines.append("")

    lines.append("### 3.2 å„åœºæ™¯è¯¦ç»†æ•°æ®")
    lines.append("")
    lines.append("| åœºæ™¯ | æ€»è€—æ—¶(s) | é¦–tokenå»¶è¿Ÿ(s) | ç”Ÿæˆtokens | ååé‡(tok/s) | GPUå³°å€¼(GB) |")
    lines.append("|------|-----------|----------------|------------|---------------|-------------|")
    for b in benchmarks:
        t = b.get("timing", {})
        m = b.get("memory", {})
        lines.append(
            f"| {b['name']} "
            f"| {t.get('total_seconds', 'N/A')} "
            f"| {t.get('time_to_first_token_seconds', 'N/A')} "
            f"| ~{b.get('output_tokens_est', 'N/A')} "
            f"| {t.get('tokens_per_second', 'N/A')} "
            f"| {m.get('gpu_peak_gb', 'N/A')} |"
        )
    lines.append("")

    # â”€â”€ 4. è¾“å…¥è¾“å‡ºç¤ºä¾‹ â”€â”€
    lines.append("## 4. è¾“å…¥è¾“å‡ºç¤ºä¾‹ï¼ˆå®é™…æ¨¡å‹è¾“å‡ºï¼‰")
    lines.append("")

    for i, b in enumerate(benchmarks, 1):
        name = b.get("name", f"åœºæ™¯{i}")
        input_text = b.get("input_text", "")
        output_text = b.get("output_text", "")
        has_media = b.get("has_media", False)
        has_extra = b.get("has_extra_images", False)

        lines.append(f"### ç¤ºä¾‹ {i}: {name}")
        lines.append("")

        media_note = ""
        if has_media:
            media_note = " [é™„å¸¦å›¾ç‰‡/è§†é¢‘]"
        elif has_extra:
            media_note = " [é™„å¸¦å›¾ç‰‡]"

        lines.append(f"**ç”¨æˆ·è¾“å…¥{media_note}ï¼š**")
        lines.append("```")
        lines.append(input_text)
        lines.append("```")
        lines.append("")
        lines.append("**æ¨¡å‹è¾“å‡ºï¼š**")
        lines.append("```")
        lines.append(output_text)
        lines.append("```")
        lines.append("")

        t = b.get("timing", {})
        lines.append(f"*è€—æ—¶: {t.get('total_seconds', '?')}s | "
                      f"é¦–token: {t.get('time_to_first_token_seconds', '?')}s | "
                      f"åå: {t.get('tokens_per_second', '?')} tok/s*")
        lines.append("")

    # â”€â”€ 5. å·²çŸ¥é™åˆ¶ â”€â”€
    lines.append("## 5. å·²çŸ¥é™åˆ¶")
    lines.append("")
    lines.append("| é™åˆ¶ | è¯´æ˜ |")
    lines.append("|------|------|")
    lines.append("| **PDF é¡µæ•°ä¸Šé™** | é»˜è®¤ä»…å¤„ç†å‰ 5 é¡µï¼ˆ`max_pages=5`ï¼‰ï¼Œè¶…é•¿æ–‡æ¡£éœ€æ‰‹åŠ¨æˆªå– |")
    lines.append("| **è§†é¢‘é•¿åº¦** | å—æ˜¾å­˜å’Œ `max_model_len` é™åˆ¶ï¼Œå»ºè®®è§†é¢‘ä¸è¶…è¿‡ 30 ç§’ |")
    lines.append("| **å¹¶å‘èƒ½åŠ›** | å•ç”¨æˆ·å•è¯·æ±‚ï¼Œä¸æ”¯æŒå¤šç”¨æˆ·å¹¶å‘æ¨ç† |")

    if backend == "vllm":
        lines.append('| **vLLM æµå¼** | vLLM åç«¯ä¸º"ä¼ªæµå¼"ï¼ˆæ•´ä½“ç”Ÿæˆååˆ†å—è¾“å‡ºï¼‰ï¼Œéé€ token æµå¼ |')
        lines.append('| **vLLM æ˜¾å­˜ç›‘æ§** | ä¿®å¤äº†ä¹‹å‰æ˜¾ç¤º 0 çš„é—®é¢˜ï¼Œç°é€šè¿‡ nvidia-smi æŠ¥å‘Šå®é™…ä½¿ç”¨ |')
    else:
        lines.append("| **Transformers æµå¼** | æ”¯æŒé€ token æµå¼è¾“å‡ºï¼Œä½“æ„Ÿå»¶è¿Ÿè¾ƒä½ |")

    lines.append("| **URL å›¾ç‰‡** | ä»…æ”¯æŒç›´é“¾å›¾ç‰‡ URLï¼Œä¸æ”¯æŒéœ€è¦ç™»å½•æˆ– JS æ¸²æŸ“çš„é¡µé¢ |")
    lines.append("| **å¤šè½®ä¸Šä¸‹æ–‡** | å†å²æ¶ˆæ¯å…¨éƒ¨æ‹¼æ¥ï¼Œè¶…é•¿å¯¹è¯å¯èƒ½è§¦å‘ OOM æˆ–è¢«æˆªæ–­ã€‚å·²æ–°å¢è‡ªåŠ¨è£å‰ªé€»è¾‘ï¼Œè¶…é•¿æ—¶ä¼šåˆ é™¤æœ€æ—©çš„è½®æ¬¡å¹¶æ’å…¥ç³»ç»Ÿæç¤º |")
    lines.append("| **CPU æ¨¡å¼** | ä»… Transformers åç«¯æ”¯æŒ `--cpu-only`ï¼Œé€Ÿåº¦ææ…¢ï¼Œä»…ä¾›è°ƒè¯• |")
    lines.append("| **æ¨¡å‹èƒ½åŠ›** | 2B å‚æ•°é‡ä¸ºè½»é‡ç‰ˆï¼Œå¤æ‚æ¨ç†å’Œé•¿æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›å¼±äºæ›´å¤§æ¨¡å‹ |")

    # æ ¹æ®å®æµ‹æ•°æ®æ·»åŠ æ˜¾å­˜ç›¸å…³é™åˆ¶
    gpu_total = summary.get("gpu_total_memory_gb", 0)
    gpu_peak = summary.get("inference_gpu_peak_max_gb", 0)
    if gpu_total and gpu_peak:
        usage_pct = (gpu_peak / gpu_total) * 100
        lines.append(f"| **æ˜¾å­˜ä½¿ç”¨ç‡** | æ¨ç†å³°å€¼å  GPU æ€»æ˜¾å­˜çš„ {usage_pct:.1f}%ï¼Œ"
                      f"é•¿ä¸Šä¸‹æ–‡æˆ–å¤šå›¾è¾“å…¥å¯èƒ½å¯¼è‡´ OOM |")

    lines.append("")

    # â”€â”€ 6. æ€§èƒ½ä¼˜åŒ–å»ºè®® â”€â”€
    lines.append("## 6. æ€§èƒ½ä¼˜åŒ–å»ºè®®")
    lines.append("")
    lines.append("1. **æ˜¾å­˜ä¸è¶³æ—¶**ï¼šé™ä½ `--max-model-len` æˆ– `--gpu-memory-utilization` å‚æ•°")
    lines.append("2. **æå‡ååé‡**ï¼šä½¿ç”¨ vLLM åç«¯ï¼ˆ`--backend vllm`ï¼‰ï¼Œé€‚åˆæ‰¹é‡æ¨ç†åœºæ™¯")
    lines.append("3. **é™ä½å»¶è¿Ÿ**ï¼šä½¿ç”¨ Transformers åç«¯çš„æµå¼è¾“å‡ºï¼Œé¦– token å»¶è¿Ÿæ›´ä½")
    lines.append("4. **é•¿æ–‡æ¡£å¤„ç†**ï¼šå‡å°‘ PDF é¡µæ•°æˆ–é™ä½å›¾ç‰‡åˆ†è¾¨ç‡ä»¥èŠ‚çœæ˜¾å­˜")
    lines.append("5. **å¤šè½®å¯¹è¯**ï¼šå®šæœŸæ¸…ç©ºä¼šè¯å†å²ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿å¯¼è‡´ OOM")
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append(f"*æœ¬æ–‡æ¡£ç”± `scripts/benchmark.py` å’Œ `scripts/generate_report.py` è‡ªåŠ¨ç”Ÿæˆ*")
    lines.append(f"*æµ‹è¯•æ—¶é—´: {timestamp}*")
    lines.append("")

    return "\n".join(lines)


def parse_args():
    parser = argparse.ArgumentParser(description="ä»åŸºå‡†æµ‹è¯•ç»“æœç”ŸæˆæŠ€æœ¯è¯´æ˜æ–‡æ¡£")
    parser.add_argument("--input", type=str, required=True,
                        help="benchmark.py ç”Ÿæˆçš„ JSON ç»“æœæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", type=str, default=None,
                        help="è¾“å‡º Markdown æ–‡ä»¶è·¯å¾„ (é»˜è®¤: TECHNICAL_REPORT.md)")
    return parser.parse_args()


def main():
    args = parse_args()
    output_path = args.output or "TECHNICAL_REPORT.md"

    print(f"ğŸ“– è¯»å–åŸºå‡†æµ‹è¯•ç»“æœ: {args.input}")
    data = load_results(args.input)

    print(f"ğŸ“ ç”ŸæˆæŠ€æœ¯è¯´æ˜æ–‡æ¡£...")
    report = generate_report(data)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"âœ… æŠ€æœ¯è¯´æ˜æ–‡æ¡£å·²ç”Ÿæˆ: {output_path}")
    print(f"   æ–‡æ¡£å¤§å°: {len(report)} å­—ç¬¦, {report.count(chr(10))} è¡Œ")


if __name__ == "__main__":
    main()
